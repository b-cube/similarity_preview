{
    "content": "<?xml version='1.0' encoding='ascii'?> <!DOCTYPE rfc SYSTEM \"rfc2629.dtd\"> <?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?> <!-- used by XSLT processors --> <!-- For a complete list and description of processing instructions (PIs),  please see http://xml.resource.org/authoring/README.html. --> <!-- Below are generally applicable Processing Instructions (PIs) that most I-Ds might want to use. (Here they are set differently than their defaults in xml2rfc v1.32) --> <?rfc strict=\"yes\" ?> <!-- give errors regarding ID-nits and DTD validation --> <!-- control the table of contents (ToC) --> <?rfc toc=\"yes\"?> <!-- generate a ToC --> <?rfc tocdepth=\"4\"?> <!-- the number of levels of subsections in ToC. default: 3 --> <!-- control references --> <?rfc symrefs=\"yes\"?> <!-- use symbolic references tags, i.e, [RFC2119] instead of [1] --> <?rfc sortrefs=\"yes\" ?> <?rfc comments=\"yes\" ?> <?rfc inline=\"yes\" ?> <!-- sort the reference entries alphabetically --> <!-- control vertical white space  (using these PIs as follows is recommended by the RFC Editor) --> <?rfc compact=\"yes\" ?> <!-- do not start each main section on a new page --> <?rfc subcompact=\"no\" ?> <!-- keep one blank line between list items --> <!-- end of list of popular I-D processing instructions --> <rfc category=\"info\" docName=\"draft-sullivan-lucid-prob-stmt-00\" ipr=\"trust200902\" obsoletes=\"\" updates=\"\" submissionType=\"IETF\" xml:lang=\"en\">   <!--category values: std, bcp, info, exp, and historic ipr values: full3667, noModification3667, noDerivatives3667 you can add the attributes updates=\"NNNN\" and obsoletes=\"NNNN\" they will automatically be output with \"(if approved)\" -->   <!--***** FRONT MATTER ***** -->   <front>     <!--The abbreviated title is used in the page header - it is only necessary if the full title is longer than 39 characters -->     <title abbrev=\"LUCID Problem Statement\">A Problem Statement to Motivate Work on Locale-free Unicode Identifiers</title>     <!--add 'role=\"editor\"' below for the editors if appropriate -->     <!--Another author who claims to be an editor -->     <author fullname=\"Andrew Sullivan\" initials=\"A.\" surname=\"Sullivan\">       <organization>Dyn</organization>       <address>         <postal>           <street>150 Dow St.</street>           <!--Reorder these if your country does things differently -->           <city>Manchester</city>           <region>NH</region>           <code>03101</code>           <country>US</country>         </postal>         <phone/>         <email>asullivan@dyn.com</email>         <!--uri and facsimile elements may also be added -->       </address>     </author>     <author fullname=\"Asmus Freytag\" initials=\"A.\" surname=\"Freytag\">       <organization>ASMUS Inc.</organization>       <address>         <email>asmus@unicode.org</email>       </address>     </author>     <date year=\"2015\"/>     <!--If the month and year are both specified and are the current ones, xml2rfc will fill in the current day for you. If only the current year is specified, xml2rfc will fill in the current day and month for you. If the year is not the current one, it is necessary to specify at least a month (xml2rfc assumes day=\"1\" if not specified for the purpose of calculating the expiry date).  With drafts it is normally sufficient to specify just the year. -->     <!--Meta-data Declarations -->     <area>General</area>     <workgroup>Internet Engineering Task Force</workgroup>     <!--WG name at the upperleft corner of the doc, IETF is fine for individual submissions.  If this element is not present, the default is \"Network Working Group\", which is used by the RFC Editor as a nod to the history of the IETF. -->     <keyword>internationalization i18n</keyword>     <!--Keywords will be incorporated into HTML output files in a meta tag but they have no effect on text or nroff output. If you submit your draft to the RFC Editor, the keywords will be used for the search engine. -->     <abstract>       <t>Internationalization techniques that the IETF has adopted       depended on some assumptions about the way characters get added       to Unicode. Some of those assumptions turn out not to have been       true. Discussion is necessary to determine how the IETF should       respond to the new understanding of how Unicode works.</t>     </abstract>   </front>   <middle>     <section title=\"Introduction\" anchor=\"sec_introduction\" toc=\"default\">       <t>Among its features, IDNA2008 <xref target=\"RFC5890\" pageno=\"false\" format=\"default\"/> <xref target=\"RFC5891\" pageno=\"false\" format=\"default\"/> <xref target=\"RFC5892\" pageno=\"false\" format=\"default\"/> <xref target=\"RFC5893\" pageno=\"false\" format=\"default\"/> <xref target=\"RFC5894\" pageno=\"false\" format=\"default\"/> <xref target=\"RFC5895\" pageno=\"false\" format=\"default\"/> provides a way of using Unicode <xref target=\"Unicode\" pageno=\"false\" format=\"default\"/> characters without regard to the version of Unicode available.  The same approach is generalized for protocols other than DNS by the PRECIS framework <xref target=\"I-D.ietf-precis-framework\" pageno=\"false\" format=\"default\"/>.</t>       <t>The mechanism used is called \"inclusion\", and is outlined in <xref target=\"sec_inclusion\" pageno=\"false\" format=\"default\"/> below.  We call the general strategy \"inclusion-based identifier internationalization\" or \"i3\" for short.  I3 depends on certain assumptions made in the IETF at the time it was being developed.  Some of those assumptions were about the relationships between various characters and the likelihood that similar such relationships would get added to future versions of Unicode.  Those assumptions turn out not to have been true in every case.  This raises a question, therefore, about whether the current approach meets the needs of the IETF for internationalizing identifiers.</t>       <t>This memo attempts to give enough background about the situation so that IETF participants can participate in a discussion about what (if anything) to do about the state of affairs; the discussion is expected to happen as part of the LUCID BoF at IETF 92.  The reader is assumed to be familiar with the terminology in <xref target=\"RFC6365\" pageno=\"false\" format=\"default\"/>.  This memo owes a great deal to the exposition in <xref target=\"I-D.klensin-idna-5892upd-unicode70\" pageno=\"false\" format=\"default\"/>.</t>     </section>     <section title=\"Background\" anchor=\"sec_background\" toc=\"default\">       <t>The intent of Unicode is to encode all known writing systems into a single coded character set.  One consequence of that goal is that Unicode encodes an enormous number of characters.  Another is that the work of Unicode does not end until every writing system is encoded; even after that, it needs to continue to track any changes in those writing systems.  Unicode encodes abstract characters, not glyphs.  Because of the way Unicode was built up over time, there are sometimes multiple ways to encode the same abstract character.  If Unicode encodes an abstract character in more than one way, then for most purposes the different encodings should all be treated as though they're the same character.  This is called \"canonical equivalence\".</t>       <t>A lack of a defined canonical equivalence is tantamount to an assertion by Unicode that the two encodings do not represent the same abstract character, even if both happen to result in the same appearance.</t>       <t>Every encoded character in Unicode (that is, every code point) is associated with a set of properties.  The properties define what script a code point is in, whether it is a letter or a number or punctuation and so forth, what direction it is written in, to what other code point or code point sequence it is canonically equivalent, and many other properties.  These properties are important to the inclusion mechanism.</t>       <section title=\"The Inclusion Mechanism\" anchor=\"sec_inclusion\" toc=\"default\">         <t>Because of both the enormous number of characters in Unicode and the many purposes it must serve, Unicode contains characters that are not well-suited for use as part of identifiers for network protocols.  The inclusion mechanism starts by assuming an empty set of characters.  It then evaluates Unicode characters not individually, but instead by classifying them according to their properties.  This classification provides the \"derived properties\" that IDNA2008 and PRECIS rely upon.</t>         <t>In practice, the inclusion mechanism includes code points that are letters or digits.  There are some ways to include or exclude characters that otherwise would be excluded or included (respectively); but it is impractical to evaluate each character, so most characters are included or excluded based on the properties they have.</t>         <t>I3 depends on the assumption that strings that will be used in identifiers will not have any ambiguous matching to other strings.  In practice, this means that input strings to the protocol are expected to be in Normalization Form C.  This way, any alternative sequences of code points for the same characters will be normalized to a single form.  Assuming then that those characters are all included by the inclusion mechanism, the string is eligible to be an identifier under the protocol.</t>       </section>       <section title=\"The Difference Between Theory and Practice\" anchor=\"sec_difference\" toc=\"default\">         <t>In principle, under i3 identifiers should be unambiguous.  It has always been recognized, however, that for humans some ambiguity was inevitable, because of the vagaries of writing systems and of human perception.</t>         <t>Normalization Form NFC removes the ambiguities based on dual or multiple encoding for the same abstract character. However, characters are not the same as their glyphs. This means that it is possible for certain abstract characters to share a glyph. We call such abstract characters \"homoglyphs\". While this looks at first like something that should be handled (or should have been handled) by normalization (NFC or something else), there are important differences; the situation is in some sense an extreme case of a spectrum of ambiguity discussed in the following section.</t>         <section title=\"Confusability\" anchor=\"sec_confusability\" toc=\"default\">           <t>While Unicode deals in abstract characters and i3 works on Unicode code points, users interact with the characters as actually rendered: glyphs.  There are characters that, depending on font, sometimes look quite similar to one another (such as \"l\" and \"1\"); any character that is like this is often called \"visually similar\".  More difficult are characters that, in any normal rendering, always look the same as one another.  The shared history of Cyrillic, Greek, and Latin scripts, for example, means that there are characters in each script that function similarly and that are usually indistinguishable from one another, though they are not the same abstract character.  These are examples of \"homoglyphs.\"  Any character that can be confused for another one can be called confusable, and confusability can be thought of as a spectrum with \"visually similar\" at one end, and \"homoglyphs\" at the other.  (We use the term \"homoglyph\" strictly: code points that normally use the same glyph when rendered.)</t>           <t>Most of the time, there is some characteristic that can help to mitigate confusion.  Mitigation may be as simple as using a font designed to distinguish among different characters.  For homoglyphs, a large number of cases (but not all of them) turn out to be in different scripts.  As a result, there is an operational convention that identifiers should always be in a single script.  (This strategy can be less than successful in cases where each identifier is in a single script, but the repertoire used in operation allows multiple scripts, because of whole string confusables -- strings made up entirely of homoglyphs of another string in a different script.)  </t>           <t>There is another convention that operators should only ever use the smallest repertoire of code points possible for their environment. So, for example, if there is a code point that is sometimes used but is perhaps a little obscure, it is better to leave it out and gain some experience with other cases first.  In particular, code points used in a language with which the administrator is not familiar should probably be excluded.  In the case of IDNA, some client programs restrict display of U-labels to top-level domains known to have policies about single-script labels.  None of these policies or convention will do anything to help strict homoglyphs of each other in the same script (see <xref target=\"sec_examples\" pageno=\"false\" format=\"default\"/> for some example cases.) </t>           <section title=\"Not everything can be solved\" anchor=\"sec_insoluble\" toc=\"default\">             <t>Before continuing, it is worth noting that there are some cases that, regardless of mitigation, are fundamentally impossible to solve.  There are certainly cases of two strings in which all the code points in one script in the first string, and all the code points in another script in the second string, are respectively confusable with one another.  In that case, the strings cannot be distinguished by a reader, and the whole string is confusable.  Further, human perception is easily tricked, so that entirely unrelated character sequences can become confusable, for example \"rn\" being confused with \"m\".</t>             <t>Given the facts of history and the contingencies of writing systems, one cannot defend against all of these cases; and it seems all but certain that many of these cases cannot successfully be addressed on the protocol level alone.  In general, the i3 strategy can only define rules for one identifier at a time, and has no way to offer guidance about how different identifiers under the same scheme ought to interact.  Humans are likely to respond according to the entire identifier string, so there seems to be a deep tension between the narrow focus of i3, and the actual experience of users.</t>             <t>In addition, several factors limit the ability to ensure that any solution adopted is final and complete: the sheer complexity of writing systems, the fact that many of them are not equally well understood as Latin or Han, and that many less developed writing systems are potentially susceptible to paradigm changes as digital support for them becomes more widespread. Detailed knowledge about, and implementation experience for, these writing systems only emerges over time; disruptive changes are neither predictable ahead of time nor preventable. In essence, any solution to eliminate ambiguity can be expected to get some detail wrong.</t>             <t>Nobody should imagine that the present discussion takes as its goal the complete elimination of all possible confusion.  The failure to achieve such a goal does not mean, however, that we should do nothing, any more than the low chances of ever arresting all grifters means that we should not enact laws against fraud.  Our discussion, then, must focus on those problems that are able to be addressed in the constraint of the protocols; and, in particular, the subset that are suitable for that</t>           </section>         </section>         <section title=\"The Problem Now Before Us\" anchor=\"sec_curr_prob\" toc=\"default\">           <t>During the expert review necessary for supporting Unicode 7.0.0 for use with IDNA, a new code point U+08A1, ARABIC LETTER BEH WITH HAMZA ABOVE came in for some scrutiny.  Using versions of Unicode up to and including 7.0.0, it is possible to combine ARABIC LETTER BEH (U+0628) and ARABIC HAMZA ABOVE (U+0654) to produce a glyph that is indistinguishable from the one produced by U+08A1.  But U+08A1 and \\\\u'0628'\\\\u'0654' are not canonically equivalent.  (For more discussion of this issue, see <xref target=\"I-D.klensin-idna-5892upd-unicode70\" pageno=\"false\" format=\"default\"/>.)</t>           <t>Further investigation reveals that there are several similar cases.  ARABIC HAMZA ABOVE (U+0654) turns out to be implicated in some cases, but not all of them.  There are cases in Latin (see <xref target=\"sec_examples\" pageno=\"false\" format=\"default\"/> for examples).  There are certainly cases in other scripts (some examples are provided in <xref target=\"sec_examples\" pageno=\"false\" format=\"default\"/>).  The majority of cases all have a handful of things in common: <list style=\"symbols\"><t>There are at least two forms by which the same glyph is produced.</t><t>One of the forms uses a combining sequence and another form is a precomposed character, or else one of the forms is a digraph. <cref source=\"ajs\">Is this true?  Are there any cases that don't match it?</cref></t><t>The results when rendered as glyphs cannot be distinguished from one another.</t><t>The two forms are not canonically equivalent.</t><t>All of the relevant code points have the same script property, or else inherit the script property of the previous character so that it is not possible to select on the basis of the script.</t><t>Competent users of the writing system in a language do not treat one of the combining sequence or the precomposed character as reasonable.  To writers for whom the combining sequence is \"wrong\", it is not a case of a base character modified by an additional mark, but instead a separate letter.  Conversely, to writers for whom the precomposed character is \"wrong\", it is definitely a matter of adding something to a character that otherwise stands on its own.  (Not every possible combination would normally be used by anyone, of course, and sometimes -- not infrequently -- one of the alternatives is not used by any orthography.)</t></list> Cases that match these conditions might be considered to involve \"non-normalizable diacritics\", because most of the combining marks in question are non-spacing marks that are or act like diacritics.  </t>         </section>       </section>     </section>     <section title=\"Identifiers\" anchor=\"sec_identifiers\" toc=\"default\">       <t>Part of the reason i3 works from the assumption that not all Unicode code points are appropriate for identifiers is that identifiers do not work like words of phrases in a language.  First, identifiers often appear in contexts where there is no way to tell the language of the identifiers.  Indeed, many identifiers are not really \"in a language\" at all.  Second, and partly because of that lack of linguistic root, identifiers are often either not words or use unusual orthography precisely to differentiate themselves.</t>       <t>In ordinary language use, the ambiguity identified in <xref target=\"sec_difference\" pageno=\"false\" format=\"default\"/> may well create no difficulty.  Running text has two properties that make this so.  First, because there is a linguistic context (the rest of the text), it is possible to detect code points that are used in an unusual way and flag them or, even, create automatic rules to \"fix\" such issues.  Second, linguistic context comes with spelling rules that automatically determine whether something is written the right way.  Because of these facts, it is often possible even without a locale identifier to work out what the locale of the text ought to be.  So, even in cases where passages of text need to be compared, it is possible to mitigate the issue.</t>       <t>The same locale-detection approach does not work for identifiers.  Worse, identifiers, by their very nature, are things that must provide reliable exact matches.  The whole point of an identifier is that it provides a reliable way of uniquely naming the thing to be identified.  Partial matches and heuristics are inadequate for those purposes.  Identifiers are often used as part of the security practices for a protocol, and therefore ambiguity in matching presents a risk for the security of any protocol relying on the identifier.</t>       <section title=\"Types of Identifiers\" anchor=\"sec_types_id\" toc=\"default\">         <t>It is worth observing that not all identifiers are of the same type.  There are four relevant dimensions in which identifiers can differ in type: <list style=\"numbers\"><t>Scope <list style=\"format (%c)\"><t>Internet-wide</t><t>Unique within a context (often a site)</t><t>Link-local only</t></list></t><t>Management <list style=\"format (%c)\"><t>Centrally managed</t><t>Contextually managed (e.g. registering a nickname with a server for a session)</t><t>Unmanaged</t></list></t><t>Durability <list style=\"format (%c)\"><t>Permanent</t><t>Durable but with possible expiration</t><t>Temporary</t><t>Ephemeral</t></list></t><t>Authority <list style=\"format (%c)\"><t>Single authority</t><t>Multiple authorities (possibly within a hierarchy)</t><t>No authority</t></list></t></list></t>         <t>These different dimensions present ways in which mitigation of the identified issue might be possible.  For instance, a protocol that uses only link-local identifiers that are unmanaged, temporary, and configured automatically does not really present a problem, because for practical purposes its linguistic context is constrained to the social realities of the LAN in question.  A durable Internet-wide identifier centrally managed by multiple authorities will present a greater issue unless locale information comes along with the identifier.</t>       </section>     </section>     <section title=\"Possible Nature of Problem\" anchor=\"sec_prob_nature\" toc=\"default\">       <t>We may regard this problem as one of several different kinds, and depending on how we view it we will have different approaches to addressing it.</t>       <section title=\"Just a Species of Confusables\" anchor=\"sec_spec_confusable\" toc=\"default\">         <t>Under this interpretation, the current issue is no different to any other confusable case, except in detail.  Since there is no way to solve the general problem of confusables, there is no way to solve this problem either.  Moreover, to the degree that confusables are solved outside protocols, by administration and policy, the current issue might be addressed by the same strategy.</t>         <t>This interpretation seems unsatisfying, because there exist some partial mitigations, and if suitable further mitigations are possible it would be wise to apply them.</t>       </section>       <section title=\"Just a Species of Homoglyphs\" anchor=\"sec_spec_homoglyph\" toc=\"default\">         <t>Under this interpretation, the current issue is no different than any other homoglyph case.  After all, the basic problem is that there is no way for a user to tell which codepoint is represented by what the user sees in either case.</t>         <t>There is some merit to this view, but it has the problem that many of the homoglyph issues (admittedly not all of them) can be mitigated through registration rules, and those rules can be established without examining the particular code points in question (that is, they can operate just on the properties of code points, such as script membership).  The current issue does not allow such mitigation given the properties that are currently available.  At the same time, it may be that it is impossible to deal with this adequately, and some judgement will be needed for what is adequate.  This is an area where more discussion is clearly needed.</t>       </section>       <section title=\"Separate Problem\" anchor=\"sec_sep_prob\" toc=\"default\">         <t>Under this interpretation, there is a definable problem, and its boundaries can be specified.</t>         <t>That we can list some necessary conditions for the problem suggests that it is a separable problem.  The list of factors in <xref target=\"sec_curr_prob\" pageno=\"false\" format=\"default\"/> seems to indicate that it is possible to describe the bounds of a problem that can be addressed separately.</t>         <t>What is not clear is whether it is separable enough to make it worth treating separately.</t>       </section>       <section title=\"Unimportant Problem\" anchor=\"sec_unimportant\" toc=\"default\">         <t>Under this interpretation, while it is possible to describe the problem, it is not a problem worth addressing since nobody would ever create such identifiers on purpose.</t>         <t>The problem with this approach, for identifiers, is that it represents an opportunity for phishing and other similar attacks.  While mitigation will not stop all such attacks, we should try to understand opportunities for those attacks and close when we have identified them and it is practical to do so.</t>         <t>Whether phishing or other attacks using confusable code points \"pay off\" depends to some extent on the popularity or frequency of the code points in question.  While it may be worth to address the generalized issue, individual edge cases may have no practical consequences. The inability to address them then, should not hold up progress on a solution for the more common, general case.</t>       </section>     </section>     <section title=\"Possible Ways Forward\" anchor=\"sec_wayforward\" toc=\"default\">       <t>There are a few ways that this issue could be mitigated.  Note that this section is closely related to Section 3 in <xref target=\"I-D.klensin-idna-5892upd-unicode70\" pageno=\"false\" format=\"default\"/>.</t>       <section title=\"Find the Cases, Disallow New Ones, and Deal                     With Old Ones\" toc=\"default\">         <t>In this case, it is necessary to enumerate all the cases, add exceptions to DISALLOW any new cases from happening, and make a determination about what to do for every past case.  There are two reasons to doubt whether this approach will work.  <list style=\"numbers\"><t>The IETF did not catch these issues during previous internationalization efforts, and it seems unlikely that in the meantime it has acquired enough expertise in writing systems to do a proper job of it this time.</t><t>This approach blunts the effectiveness of being Unicode version-agnostic, since it would effectively block any future additions to Unicode that had any interaction with the present version.</t></list></t>         <t>So, this approach does not seem too promising.</t>       </section>       <section title=\"Disallow Certain Combining Sequences                     Absolutely\" anchor=\"sec_disallow\" toc=\"default\">         <t>In this case, instead of treating all the code points in Unicode, the IETF would need only to look at all combining characters.  While the IETF obviously does not have the requisite expertise in writing systems to do this unilaterally, the Unicode Consortium does.  In fact the Unicode Technical Committee has a clear understanding that some combining sequences are never intended to be used for orthographic purposes.  Any glyph needed for an orthography or writing system will, once identified, be added as a single code point with \"pre-composed\" glyph.</t>         <t>In principle there is no obstacle, in these cases, to asking Unicode to express this understanding in form of a character property, which then means that IETF could DISALLOW the combining marks having such a property.</t>       </section>       <section title=\"Do Nothing, Possibly Warn\" toc=\"default\">         <t>One possibility is to accept that there is nothing one can do in general here, and that therefore the best one can do is warn people to be careful.</t>         <t>The problem with this approach, of course, is that it all but guarantees future problems with ambiguous identifiers.  It would provide a good reason to reject all internationalized identifiers as representing a significant security risk, and would therefore mean that internationalized identifiers would become \"second class\".  Unfortunately, however, the demand for internationalized identifiers would not likely be reduced by this decision, so some people would end up using identifiers with known security problems.</t>         <t>This approach may be the only possible in some of the borderline cases where mitigation approaches are not successful.</t>       </section>       <section title=\"Identify Enough Commonality for a New                     Property\" anchor=\"sec_new_prop\" toc=\"default\">         <t>There is reason to suppose that, if the IETF can come up with clear and complete conditions under which code points causing an issue could be classified, the Unicode Technical Committee would add such a property to code points in future versions of the Unicode Standard.  Assuming the conditions were clear, future additions to the Standard could also be assigned appropriate values of the property, meaning that the IETF could revert to making decisions about code points based on derived properties.  Beyond the property mentioned in <xref target=\"sec_disallow\" pageno=\"false\" format=\"default\"/> this property could cover certain combining marks in the Arabic script.</t>         <t>If this is possible, it seems a desirable course of action.</t>       </section>       <section title=\"Create an IETF-only Normalization Form\" toc=\"default\">         <t>Under this approach, the IETF creates a special normalization form that it maintains outside the Unicode Standard.  For the sake of the discussion, we'll call this \"NFI\".</t>         <t>This option does not seem workable.  The IETF would have to evaluate every new release of Unicode to discover the extent to which the new release interacts with NFI.  Because it would be independently maintained, Unicode stability guarantees would not apply to NFI; the results would be unpredictable.  As a result, either the IETF would have to ignore new additions to Unicode, or else it would need UTC to take NFI into account.  If UTC were able to do so, this option reduces to the option in <xref target=\"sec_new_prop\" pageno=\"false\" format=\"default\"/>.  The UTC might not be able to do this, however, because the very principles that Unicode uses to assign new characters in certain situations guarantees that new characters will be added that cannot be so normalized and yet are essential for still-to-be-encoded writing systems. Communities for which these new characters would be added would also not accept any existing code point sequence as equivalent.  This also means that Unicode cannot create a stability policy to take into account the needs of such an NFI.</t>       </section>     </section>     <section anchor=\"Acknowledgements\" title=\"Acknowledgements\" toc=\"default\">       <t>The discussion in this memo owes a great deal to the IAB Internationalization program, and particularly to John Klensin.</t>     </section>   </middle>   <back>     <references title=\"Informative References\">       <reference anchor=\"RFC5890\">         <front>           <title>Internationalized Domain Names for Applications (IDNA): Definitions and Document Framework</title>           <author initials=\"J.\" surname=\"Klensin\" fullname=\"J. Klensin\">             <organization/>           </author>           <date year=\"2010\" month=\"August\"/>           <abstract>             <t>This document is one of a collection that, together, describe the protocol and usage context for a revision of Internationalized Domain Names for Applications (IDNA), superseding the earlier version.  It describes the document collection and provides definitions and other material that are common to the set. [STANDARDS-TRACK]</t>           </abstract>         </front>         <seriesInfo name=\"RFC\" value=\"5890\"/>         <format type=\"TXT\" octets=\"54245\" target=\"http://www.rfc-editor.org/rfc/rfc5890.txt\"/>       </reference>       <reference anchor=\"RFC5891\">         <front>           <title>Internationalized Domain Names in Applications (IDNA): Protocol</title>           <author initials=\"J.\" surname=\"Klensin\" fullname=\"J. Klensin\">             <organization/>           </author>           <date year=\"2010\" month=\"August\"/>           <abstract>             <t>This document is the revised protocol definition for Internationalized Domain Names (IDNs).  The rationale for changes, the relationship to the older specification, and important terminology are provided in other documents.  This document specifies the protocol mechanism, called Internationalized Domain Names in Applications (IDNA), for registering and looking up IDNs in a way that does not require changes to the DNS itself.  IDNA is only meant for processing domain names, not free text. [STANDARDS-TRACK]</t>           </abstract>         </front>         <seriesInfo name=\"RFC\" value=\"5891\"/>         <format type=\"TXT\" octets=\"38105\" target=\"http://www.rfc-editor.org/rfc/rfc5891.txt\"/>       </reference>       <reference anchor=\"RFC5892\">         <front>           <title>The Unicode Code Points and Internationalized Domain Names for Applications (IDNA)</title>           <author initials=\"P.\" surname=\"Faltstrom\" fullname=\"P. Faltstrom\">             <organization/>           </author>           <date year=\"2010\" month=\"August\"/>           <abstract>             <t>This document specifies rules for deciding whether a code point, considered in isolation or in context, is a candidate for inclusion in an Internationalized Domain Name (IDN).&lt;/t&gt;&lt;t&gt; It is part of the specification of Internationalizing Domain Names in Applications 2008 (IDNA2008). [STANDARDS-TRACK]</t>           </abstract>         </front>         <seriesInfo name=\"RFC\" value=\"5892\"/>         <format type=\"TXT\" octets=\"187370\" target=\"http://www.rfc-editor.org/rfc/rfc5892.txt\"/>       </reference>       <reference anchor=\"RFC5893\">         <front>           <title>Right-to-Left Scripts for Internationalized Domain Names for Applications (IDNA)</title>           <author initials=\"H.\" surname=\"Alvestrand\" fullname=\"H. Alvestrand\">             <organization/>           </author>           <author initials=\"C.\" surname=\"Karp\" fullname=\"C. Karp\">             <organization/>           </author>           <date year=\"2010\" month=\"August\"/>           <abstract>             <t>The use of right-to-left scripts in Internationalized Domain Names (IDNs) has presented several challenges.  This memo provides a new Bidi rule for Internationalized Domain Names for Applications (IDNA) labels, based on the encountered problems with some scripts and some shortcomings in the 2003 IDNA Bidi criterion. [STANDARDS-TRACK]</t>           </abstract>         </front>         <seriesInfo name=\"RFC\" value=\"5893\"/>         <format type=\"TXT\" octets=\"38870\" target=\"http://www.rfc-editor.org/rfc/rfc5893.txt\"/>       </reference>       <reference anchor=\"RFC5894\">         <front>           <title>Internationalized Domain Names for Applications (IDNA): Background, Explanation, and Rationale</title>           <author initials=\"J.\" surname=\"Klensin\" fullname=\"J. Klensin\">             <organization/>           </author>           <date year=\"2010\" month=\"August\"/>           <abstract>             <t>Several years have passed since the original protocol for Internationalized Domain Names (IDNs) was completed and deployed.  During that time, a number of issues have arisen, including the need to update the system to deal with newer versions of Unicode.  Some of these issues require tuning of the existing protocols and the tables on which they depend.  This document provides an overview of a revised system and provides explanatory material for its components.  This document is not an Internet Standards Track specification; it is published for informational purposes.</t>           </abstract>         </front>         <seriesInfo name=\"RFC\" value=\"5894\"/>         <format type=\"TXT\" octets=\"115174\" target=\"http://www.rfc-editor.org/rfc/rfc5894.txt\"/>       </reference>       <reference anchor=\"RFC5895\">         <front>           <title>Mapping Characters for Internationalized Domain Names in Applications (IDNA) 2008</title>           <author initials=\"P.\" surname=\"Resnick\" fullname=\"P. Resnick\">             <organization/>           </author>           <author initials=\"P.\" surname=\"Hoffman\" fullname=\"P. Hoffman\">             <organization/>           </author>           <date year=\"2010\" month=\"September\"/>           <abstract>             <t>In the original version of the Internationalized Domain Names in Applications (IDNA) protocol, any Unicode code points taken from user input were mapped into a set of Unicode code points that \"made sense\", and then encoded and passed to the domain name system (DNS).  The IDNA2008 protocol (described in RFCs 5890, 5891, 5892, and 5893) presumes that the input to the protocol comes from a set of \"permitted\" code points, which it then encodes and passes to the DNS, but does not specify what to do with the result of user input.  This document describes the actions that can be taken by an implementation between receiving user input and passing permitted code points to the new IDNA protocol.  This document is not an Internet Standards Track specification; it is published for informational purposes.</t>           </abstract>         </front>         <seriesInfo name=\"RFC\" value=\"5895\"/>         <format type=\"TXT\" octets=\"16556\" target=\"http://www.rfc-editor.org/rfc/rfc5895.txt\"/>       </reference>       <reference anchor=\"RFC6365\">         <front>           <title>Terminology Used in Internationalization in the IETF</title>           <author initials=\"P.\" surname=\"Hoffman\" fullname=\"P. Hoffman\">             <organization/>           </author>           <author initials=\"J.\" surname=\"Klensin\" fullname=\"J. Klensin\">             <organization/>           </author>           <date year=\"2011\" month=\"September\"/>           <abstract>             <t>This document provides a list of terms used in the IETF when discussing internationalization.  The purpose is to help frame discussions of internationalization in the various areas of the IETF and to help introduce the main concepts to IETF participants.  This memo documents an Internet Best Current Practice.</t>           </abstract>         </front>         <seriesInfo name=\"BCP\" value=\"166\"/>         <seriesInfo name=\"RFC\" value=\"6365\"/>         <format type=\"TXT\" octets=\"103155\" target=\"http://www.rfc-editor.org/rfc/rfc6365.txt\"/>       </reference>       <reference anchor=\"I-D.ietf-precis-framework\">         <front>           <title>PRECIS Framework: Preparation, Enforcement, and Comparison of Internationalized Strings in Application Protocols</title>           <author initials=\"P\" surname=\"Saint-Andre\" fullname=\"Peter Saint-Andre\">             <organization/>           </author>           <author initials=\"M\" surname=\"Blanchet\" fullname=\"Marc Blanchet\">             <organization/>           </author>           <date month=\"February\" day=\"19\" year=\"2015\"/>           <abstract>             <t>Application protocols using Unicode characters in protocol strings need to properly handle such strings in order to enforce internationalization rules for strings placed in various protocol slots (such as addresses and identifiers) and to perform valid comparison operations (e.g., for purposes of authentication or authorization).  This document defines a framework enabling application protocols to perform the preparation, enforcement, and comparison of internationalized strings (\"PRECIS\") in a way that depends on the properties of Unicode characters and thus is agile with respect to versions of Unicode.  As a result, this framework provides a more sustainable approach to the handling of internationalized strings than the previous framework, known as Stringprep (RFC 3454).  This document obsoletes RFC 3454.</t>           </abstract>         </front>         <seriesInfo name=\"Internet-Draft\" value=\"draft-ietf-precis-framework-23\"/>         <format type=\"TXT\" target=\"http://www.ietf.org/internet-drafts/draft-ietf-precis-framework-23.txt\"/>       </reference>       <reference anchor=\"I-D.klensin-idna-5892upd-unicode70\">         <front>           <title>IDNA Update for Unicode 7.0.0</title>           <author initials=\"J\" surname=\"Klensin\" fullname=\"John Klensin\">             <organization/>           </author>           <author initials=\"P\" surname=\"F&#228;ltstr&#246;m\" fullname=\"Patrik F&#228;ltstr&#246;m\">             <organization/>           </author>           <date month=\"January\" day=\"6\" year=\"2015\"/>           <abstract>             <t>The current version of the IDNA specifications anticipated that each new version of Unicode would be reviewed to verify that no changes had been introduced that required adjustments to the set of rules and, in particular, whether new exceptions or backward compatibility adjustments were needed.  That review was conducted for Unicode 7.0.0 and identified a potentially problematic new code point.  This specification discusses that code point and associated issues and updates RFC 5892 accordingly.  It also applies an editorial clarification that was the subject of an earlier erratum.  In addition, the discussion of the specific issue updates RFC 5894.</t>           </abstract>         </front>         <seriesInfo name=\"Internet-Draft\" value=\"draft-klensin-idna-5892upd-unicode70-03\"/>         <format type=\"TXT\" target=\"http://www.ietf.org/internet-drafts/draft-klensin-idna-5892upd-unicode70-03.txt\"/>       </reference>       <reference anchor=\"Unicode\" target=\"\">         <front>           <title>The Unicode Standard</title>           <author initials=\"\" surname=\"\" fullname=\"\">             <organization/>           </author>           <date month=\"\" year=\"\"/>         </front>         <seriesInfo name=\"\" value=\"http://www.unicode.org/versions/Unicode7.0.0/\"/>       </reference>     </references>     <section anchor=\"sec_examples\" title=\"Examples\" toc=\"default\">       <t>There are a number of cases that illustrate the combining sequence or digraph issue: <list style=\"hanging\"><t hangText=\"U+08A1 vs \\\\u'0628'\\\\u'0654'\">This case is ARABIC LETTER BEH WITH HAMZA ABOVE, which is the one that was detected during expert review that caused the IETF to notice the issue.  The issue existed before this, but we did not know it.  For detailed discussion of this case and some of the following ones, see <xref target=\"I-D.klensin-idna-5892upd-unicode70\" pageno=\"false\" format=\"default\"/></t><t hangText=\"U+0681 vs \\\\u'062D'\\\\u'0654'\">This case is ARABIC LETTER HAH WITH HAMZA ABOVE, which (like U+08A1) does not have a canonical equivalent.  In both cases, the places where hamza above are used are specialized enough that the combining marks can be excluded in some cases (for example, the root zone under IDNA).</t><t hangText=\"U+0623 vs \\\\u'0627'\\\\u'0654'\">This case is ARABIC LETTER ALEF WITH HAMZA ABOVE.  Unlike the previous two cases, it does have a canonical equivalence with the combining sequence.  In the past, the IETF misunderstood the reasons for the difference between this pair and the previous two cases.</t><t hangText=\"U+09E1 vs u\\\\'098C'u\\\\'09E2'\">This case is BENGALI LETTER VOCALIC LL.  This is an example in Bengali script of a case without a canonical equivalence to the combining sequence.  Per Unicode, the single code point should be used to represent vowel letters in text, and the sequence of code points should not be used.  But it is not a simple matter of disallowing the combining vowel mark in cases like this; where the combination does not exist and the use of the sequence is already established, Unicode is unlikely to encode the combination. </t><t hangText=\"U+019A vs \\\\u'006C'\\\\u'0335'\">This case is LATIN SMALL LETTER L WITH BAR.  In at least some fonts, there is a detectable difference with the combining sequence, but only if one types them one after another and compares them.  There is no canonical equivalence here.  Unicode has a principle of encoding barred letters as composites when needed for any writing system.</t><t hangText=\"U+00F8 vs \\\\u'006F'\\\\u'0337'\">This is LATIN SMALL LETTER O WITH STROKE.  The effect are similar to the previous case. Unicode has a principle of encoding stroked letters as composites when needed for any writing system.</t><t hangText=\"U+02A6 vs \\\\u'0074'\\\\u'0073'\">This is LATIN SMALL LETTER TS DIGRAPH, which is not canonically equivalent to the letters t and s.  The intent appears to be that the digraph shows the two shapes as kerned, but the difference may be slight out of context.</t><t hangText=\"U+01C9 vs \\\\u'006C'\\\\u'006A'\">Unlike the TS digraph, the LJ digraph has a relevant compatibility decomposition, so it fails the relevant stability rules under i3 and is therefore DISALLOWED.  This illustrates the way that consistencies that might be natural to some users of a script are not necessarily found in it, possibly because of uses by another writing system.</t><t hangText=\"U+06C8 vs u\\\\'0648'u\\\\'0670'\">ARABIC LETTER YU is an example where the normally-rendered character looks just like a combining sequence, but are named differently.  In other words, this is an example where the simple fact of the Unicode name would have concealed the apparent relationship from the casual observer.</t><t hangText=\"U+069 vs \\\\u'0069'\\\\u'0307'\">LATIN SMALL LETTER I followed by COMBINING DOT ABOVE by definition, renders exactly the same as LATIN SMALL LETTER I by itself and does so in practice for any good font. The same would be true if \"i\" was replaced with any of the other Soft_Dotted characters defined in Unicode. The character sequence \\\\u'0069'\\\\u'0307' (followed by no other combining mark) is reportedly rather common on the Internet. Because base character and stand-alone code point are the same in this case, and the code points affected have the Soft_Dotted property already, this could be mitigated separately via a context rule affecting U+0307.</t></list></t>       <t>Other cases test the claim that the issue lies primarily with combining sequences at all: <list style=\"hanging\"><t hangText=\"U+0B95 vs U+0BE7\">The TAMIL LETTER KA and TAMIL DIGIT ONE are always indistinguishable, but needed to be encoded separately because one is a letter and the other is a digit.</t><t hangText=\"Arabic-Indic Digits vs. Extended Arabic-Indic       Digits\">Seven digits of these two sequences have entirely identical shapes.  This case is an example of something dealt with in i3 that nevertheless can lead to confusions that are not fully mitigated.  IDNA, for example, contains context rules restricting the digits to one set or another; but such rules apply only to a single label, not to an entire name.  Moreover, it provides no way of distinguishing between two labels that both conform to the context rule, but where each contains one of the seven identical shapes.</t><t hangText=\"U+53E3 vs U+56D7\">These are two Han characters (roughly rectangular) that are different when laid side by side; but they may be impossible to distinguish out of context or in small print.</t></list></t>     </section>   </back> </rfc> ", 
    "identity": {
        "subtype": "", 
        "is_error": false, 
        "version": "", 
        "protocol": "", 
        "language": "", 
        "service": "", 
        "has_dataset": false, 
        "has_metadata": false
    }, 
    "digest": "442ca2cbb792287ac0b77068cd8fce6d", 
    "source_url": "http://tools.ietf.org/id/draft-sullivan-lucid-prob-stmt-00.xml"
}