{
    "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?> <feed xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns=\"http://www.w3.org/2005/Atom\"> <title>School of Informatics</title> <link href=\"http://hdl.handle.net/10283/242\" rel=\"alternate\"/> <subtitle/> <id>http://hdl.handle.net/10283/242</id> <updated>2015-03-19T06:35:15Z</updated> <dc:date>2015-03-19T06:35:15Z</dc:date> <entry> <title>Visual and Linguistic Treebank</title> <link href=\"http://hdl.handle.net/10283/620\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/620</id> <updated>2015-02-23T10:53:34Z</updated> <published>2014-09-04T09:59:38Z</published> <summary type=\"text\">Visual and Linguistic Treebank The Visual and Linguistic Treebank is a data set of images annotated with human-written descriptions, object boundaries, and Visual Dependency Representations. The images are freely available from the Action Recognition Task in the PASCAL VOC 2010 data set; our annotations are available for only the trainval data. Descriptions are available for all 2,424 images in the trainval data, and object annotations and Visual Dependency Representations are available for a subset of 341 images. </summary> <dc:date>2014-09-04T09:59:38Z</dc:date> </entry> <entry> <title>Sharvard_IJA</title> <link href=\"http://hdl.handle.net/10283/574\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/574</id> <updated>2015-02-23T10:53:34Z</updated> <published>2014-07-28T14:45:07Z</published> <summary type=\"text\">Sharvard_IJA Two native Spanish talkers (one male, one female) recorded producing 700 Spanish sentences designed to be the Spanish equivalent of the English language Harvard sentences (thus phonetically balanced across sets of ten sentences).  The corpus is described in: Aubanel, V., Garc\\ufffd\\ufffda Lecumberri, M. L. and Cooke, M. \"The Sharvard Corpus: A phonemically-balanced Spanish sentence resource for audiology\", International Journal of Audiology, 2014, May 26:1-6. DOI: 10.3109/14992027.2014.907507 </summary> <dc:date>2014-07-28T14:45:07Z</dc:date> </entry> <entry> <title>Repeated Harvard Speech corpus version 0.5</title> <link href=\"http://hdl.handle.net/10283/561\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/561</id> <updated>2015-02-23T10:53:36Z</updated> <published>2014-06-19T16:54:09Z</published> <summary type=\"text\">Repeated Harvard Speech corpus version 0.5 Studio recording of female native British English talker producing three sets of Harvard sentences (thirty prompts), each prompt repeated forty times.  Available both as unprocessed 96 kHz recordings and standardised 16 kHz files. </summary> <dc:date>2014-06-19T16:54:09Z</dc:date> </entry> <entry> <title>Hurricane natural speech corpus</title> <link href=\"http://hdl.handle.net/10283/347\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/347</id> <updated>2015-02-23T10:53:36Z</updated> <published>2013-10-01T15:05:42Z</published> <summary type=\"text\">Hurricane natural speech corpus Single male native British-English talker recorded producing three speech sets (Harvard sentences, Modified Rhyme Test, news sentences) in quiet and while the talker was listening to speech-shaped noise at 84dB(A). </summary> <dc:date>2013-10-01T15:05:42Z</dc:date> </entry> <entry> <title>DiapixFL</title> <link href=\"http://hdl.handle.net/10283/346\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/346</id> <updated>2015-02-23T10:53:36Z</updated> <published>2013-10-01T14:49:04Z</published> <summary type=\"text\">DiapixFL DiapixFL consists of speakers whose first language (L1) is either English or Spanish solving a \"spot-the-difference\" task in both their L1 and their second language (L2, which for native English talkers is Spanish, and for native Spanish talkers is English). Speakers with English as an L1 were recorded at the Centre for Speech Technology at the University of Edinburgh (www.cstr.ed.ac.uk); speakers with Spanish as an L1 were recorded at the Language and Speech Laboratory at the University of the Basque Country (www.laslab.org). Six pairs of talkers in each L1 were recorded. </summary> <dc:date>2013-10-01T14:49:04Z</dc:date> </entry> <entry> <title>Sharvard</title> <link href=\"http://hdl.handle.net/10283/344\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/344</id> <updated>2015-02-23T10:53:36Z</updated> <published>2013-09-24T13:34:17Z</published> <summary type=\"text\">Sharvard Two native Spanish talkers (one male, one female) recorded producing 720 Spanish sentences designed to be the Spanish equivalent of the English language Harvard sentences (thus phonetically balanced across sets of ten sentences). </summary> <dc:date>2013-09-24T13:34:17Z</dc:date> </entry> <entry> <title>Acted clear speech corpus</title> <link href=\"http://hdl.handle.net/10283/343\" rel=\"alternate\"/> <author> <name/> </author> <id>http://hdl.handle.net/10283/343</id> <updated>2015-02-23T10:53:36Z</updated> <published>2013-09-24T12:58:20Z</published> <summary type=\"text\">Acted clear speech corpus Single male native British English talker recorded producing 25 TIMIT sentences in 5 conditions, two natural: (i) quiet, (ii) while the talker listened to high-intensity speech-shaped noise, and three acted: (i) as if to a non-native listener, (ii) as if to a computer speech-recognition system, (iii) as if to an infant. Accompanied by automatic and hand-corrected phone-level transcription. </summary> <dc:date>2013-09-24T12:58:20Z</dc:date> </entry> </feed> ", 
    "identity": {
        "subtype": "", 
        "is_error": false, 
        "version": "", 
        "protocol": "", 
        "language": "", 
        "service": "", 
        "has_dataset": false, 
        "has_metadata": false
    }, 
    "digest": "4d203840edea7e23eb70ac6a3d33edff", 
    "source_url": "http://datashare.is.ed.ac.uk/feed/atom_1.0/10283/242"
}